{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae6472d-3bff-4003-b133-ec26cdd4944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets indexed to NUMERO\n",
      "Any infinite values? False\n",
      "Any NaN values? False\n",
      "Data scaled and transformed.\n",
      "The amount of explained variance of the SES score using each component is...\n",
      "[0.71669885 0.27779474 0.00550641]\n",
      "The amount of explained variance of the SES score is: 0.71670\n",
      "        he_pct_11  kw_pct_11  median_price_inf_11    SES_11  he_pct_21  \\\n",
      "NUMERO                                                                   \n",
      "1.0      0.406723   0.599782          2361.290759  1.036947   0.465421   \n",
      "2.0      0.431287   0.574980          2846.996138  1.733345   0.448143   \n",
      "3.0      0.459283   0.490313          1581.765436 -0.268187   0.374677   \n",
      "4.0      0.279857   0.410714          1659.015611 -0.627132   0.320693   \n",
      "6.0      0.144837   0.257496          1778.834742 -1.017655   0.145476   \n",
      "7.0      0.125286   0.277738          2017.285959 -0.654012   0.147358   \n",
      "8.0      0.177477   0.331692          2089.150808 -0.341627   0.191019   \n",
      "9.0      0.226822   0.332487          1728.567912 -0.788319   0.231752   \n",
      "10.0     0.149992   0.291246          2018.081334 -0.582062   0.181493   \n",
      "\n",
      "        kw_pct_21  median_price_inf_21    SES_21  \n",
      "NUMERO                                            \n",
      "1.0      0.589041          3097.220365  2.187764  \n",
      "2.0      0.581111          3240.393552  2.351693  \n",
      "3.0      0.506631          1597.417020 -0.346214  \n",
      "4.0      0.451667          1827.690669 -0.220634  \n",
      "6.0      0.273790          1971.295289 -0.697494  \n",
      "7.0      0.282869          2295.304323 -0.198661  \n",
      "8.0      0.341416          2100.426500 -0.281047  \n",
      "9.0      0.364856          1590.334323 -0.909894  \n",
      "10.0     0.310847          2004.122520 -0.506908  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import decomposition  \n",
    "from sklearn.preprocessing import scale  \n",
    "from sklearn import preprocessing \n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "#from sklearn import cross_validation\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "### Importar Datos\n",
    "\n",
    "## 2011\n",
    "\n",
    "df_vivienda_2011 = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Variables\\01  - Precio Vivienda\\Distritos\\2011_Distritos_PrecioVivienda_V2.csv\", sep=\";\")\n",
    "df_ocupacion_2011 = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Variables\\03 - Ocupacion\\Distritos\\2011_Distritos_Ocupacion_V2.csv\", sep=\";\")\n",
    "df_estudios_2011 = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Variables\\04  - Estudios\\Distritos\\2011_Distritos_Estudios_Detalle_V2.csv\", sep=\";\")\n",
    "\n",
    "## 2016\n",
    "\n",
    "df_vivienda_2021 = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Variables\\01  - Precio Vivienda\\Distritos\\2021_Distritos_PrecioVivienda_V2.csv\", sep=\";\")\n",
    "df_ocupacion_2021 = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Variables\\03 - Ocupacion\\Distritos\\2021_Distritos_Ocupacion_V2.csv\", sep=\";\")\n",
    "df_estudios_2021 = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Variables\\04  - Estudios\\Distritos\\2021_Distritos_Estudios_Detalle_V2.csv\", sep=\";\")\n",
    "\n",
    "path_scores = r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Scores\"\n",
    "path_analytical = r\"C:\\Users\\Usuario\\OneDrive\\Escritorio\\UOC\\TFM\\PEC3  - Implementacion\\WorkStation\\Datos\\Analytical\"\n",
    "\n",
    "#print(df_vivienda_2011.describe())\n",
    "#print(df_vivienda_2021.describe())\n",
    "#print(df_ocupacion_2011.describe())\n",
    "#print(df_ocupacion_2021.describe())\n",
    "#print(df_estudios_2011.describe())\n",
    "#print(df_estudios_2021.describe())\n",
    "\n",
    "#Checks no haya nulos\n",
    "\n",
    "#Eliminar Martiricos-La Roca porque no hay datos de 2011 en vivienda\n",
    "df_estudios_2011 = df_estudios_2011[df_estudios_2011['NUMERO'] != 5]\n",
    "df_estudios_2021 = df_estudios_2021[df_estudios_2021['NUMERO'] != 5]\n",
    "df_ocupacion_2011 = df_ocupacion_2011[df_ocupacion_2011['NUMERO'] != 5]\n",
    "df_ocupacion_2021 = df_ocupacion_2021[df_ocupacion_2021['NUMERO'] != 5]\n",
    "df_vivienda_2011 = df_vivienda_2011[df_vivienda_2011['NUMERO'] != 5]\n",
    "df_vivienda_2021 = df_vivienda_2021[df_vivienda_2021['NUMERO'] != 5]\n",
    "\n",
    "dfs11 = [df_estudios_2011,df_ocupacion_2011,df_vivienda_2011]\n",
    "dfs21 = [df_estudios_2021,df_ocupacion_2021,df_vivienda_2021]\n",
    "\n",
    "df11 = pd.concat([df.set_index('NUMERO') for df in dfs11], axis=1)\n",
    "df21 = pd.concat([df.set_index('NUMERO') for df in dfs21], axis=1)\n",
    "\n",
    "print(\"Datasets indexed to NUMERO\")\n",
    "\n",
    "df11 = df11[[\"he_pct\",\"kw_pct\",\"median_price_inf\"]]\n",
    "df21 = df21[[\"he_pct\",\"kw_pct\",\"median_price_inf\"]]\n",
    "\n",
    "#print(df11)\n",
    "#print(df21)\n",
    "\n",
    "checks = {\n",
    "    \"Qualifications 2011\":df11[\"he_pct\"],\n",
    "    \"Qualifications 2021\":df21[\"he_pct\"],\n",
    "    \"Occupations 2011\":df11[\"kw_pct\"],\n",
    "    \"Occupations 2021\":df21[\"kw_pct\"],\n",
    "    \"House Prices 2011\":df11[\"median_price_inf\"],\n",
    "    \"House Prices 2021\":df21[\"median_price_inf\"],\n",
    "}\n",
    "\n",
    "for k, v in checks.items():\n",
    "    if (np.isnan(v.values).any()):\n",
    "        print(\"Have null values in data set: \" + k)\n",
    "\n",
    "\n",
    "#  Create dataset of indicator data - 2001\n",
    "res_11 = pd.concat([df11[\"he_pct\"],df11[\"kw_pct\"],df11[\"median_price_inf\"]], axis=1)\n",
    "res_21 = pd.concat([df21[\"he_pct\"],df21[\"kw_pct\"],df21[\"median_price_inf\"]], axis=1)\n",
    "\n",
    "# Create dataset of indicator data\n",
    "X_11 = res_11.values\n",
    "X_21 = res_21.values\n",
    "\n",
    "#  Join 2001 and 2011 datasets and sanity-check\n",
    "SES_inds = np.concatenate((X_11, X_21), axis=0)\n",
    "\n",
    "#print(SES_inds)\n",
    "\n",
    "print(\"Any infinite values? \" + str(~np.isfinite(SES_inds).any()))\n",
    "print(\"Any NaN values? \" + str(np.isnan(SES_inds).any()))\n",
    "\n",
    "#  Median removal and Unit scaling\n",
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(SES_inds)\n",
    "SES_inds = scaler.transform(SES_inds)\n",
    "\n",
    "print(\"Data scaled and transformed.\")\n",
    "\n",
    "pca_full = decomposition.PCA()                           # Use all Principal Components\n",
    "pca_full.fit(SES_inds)                                   # Train model on data\n",
    "SES_full_T = pd.DataFrame(pca_full.transform(SES_inds))  # Transform data using model\n",
    "\n",
    "print(\"The amount of explained variance of the SES score using each component is...\")\n",
    "print(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Adapted from https://stackoverflow.com/questions/22984335/recovering-features-names-of-explained-variance-ratio-in-pca-with-sklearn\n",
    "i = np.identity(SES_inds.shape[1])  # identity matrix\n",
    "\n",
    "coef = pca_full.transform(i)\n",
    "\n",
    "loadings = pd.DataFrame(coef, index=res_11.columns)\n",
    "loadings.to_csv(os.path.join(path_scores,\"NoTransform\" + '-Loadings-2021.csv.gz'), compression='gzip', index=True, sep=\";\")\n",
    "\n",
    "#  Fitting PCA Model to derive SES score\n",
    "pca = decomposition.PCA(n_components=1)             # Only need 1st Principal Component\n",
    "pca.fit(SES_inds)                                   #  Train model on data\n",
    "SES_inds_T = pd.DataFrame(pca.transform(SES_inds))  #  Transform data using model\n",
    "\n",
    "print(\"The amount of explained variance of the SES score is: {0:6.5f}\".format(pca.explained_variance_ratio_[0]))\n",
    "\n",
    "#  Split transformed data into 2011 and 2021 datasets\n",
    "#  Note the way we do this to deal with missing data (if any)\n",
    "scores_11 = SES_inds_T.loc[0:len(X_11)-1,0]\n",
    "scores_21 = SES_inds_T.loc[len(X_21):,0]\n",
    "\n",
    "# Create dfs from the two sets of scores\n",
    "res_11 = res_11.assign(scores=pd.Series(scores_11).values)\n",
    "res_21 = res_21.assign(scores=pd.Series(scores_21).values)\n",
    "\n",
    "#res.columns = ['LSOANM','PRICE-01','QUALS-01','OCC-01','INCOME-01','PRICE-11',\n",
    "#               'QUALS-11','OCC-11','INCOME-11','SES_01','SES_11']\n",
    "\n",
    "# Join them together so we've got a single df for 2011 and 2021\n",
    "res = res_11.merge(res_21, how='outer', suffixes=('_11','_21'), left_index=True, right_index=True)\n",
    "\n",
    "# Rename columns for consistency with Jordan's code\n",
    "res.rename(columns={'scores_11':'SES_11', 'scores_21':'SES_21'}, inplace=True)\n",
    "\n",
    "# Sanity check\n",
    "print(res.head(9))\n",
    "\n",
    "#  Compute rank of LSOA in 2011 (so low rank = 'low status')\n",
    "res['RANK_11'] = res.SES_11.rank(ascending=False)\n",
    "\n",
    "#  Compute rank of LSOA in 2021 (so low rank = 'low status')\n",
    "res['RANK_21'] = res.SES_21.rank(ascending=False)\n",
    "\n",
    "#  Compute amount by which LSOA has ascended (so +ve = status improvement; -ve = status decline)\n",
    "res.loc[:,'SES_ASC'] = res.loc[:,'SES_21'] - res.loc[:,'SES_11']\n",
    "\n",
    "import re \n",
    "#  Calculate LSOA percentile score in 01\n",
    "res.loc[:,'SES_PR_11'] = res.RANK_11.rank(ascending=False, pct=True) * 100\n",
    "\n",
    "#  Calculate LSOA percentile score in 11\n",
    "res.loc[:,'SES_PR_21'] = res.RANK_21.rank(ascending=False, pct=True) * 100\n",
    "\n",
    "#  Calculate percentile change (so +ve = 'moved up' in the world; -ve = 'moved down')\n",
    "res.loc[:,'SES_PR_ASC'] = res.loc[:,'SES_PR_21'] - res.loc[:,'SES_PR_11']\n",
    "\n",
    "inp = res.loc[:,[x for x in res.columns if 'SES' not in x and 'RANK' not in x]]\n",
    "\n",
    "# Tidy up the naming\n",
    "inp.rename(columns=lambda x: re.sub('_21',' 2021',re.sub('_11',' 2011',x)), inplace=True)\n",
    "inp.rename(columns=lambda x: re.sub('kw_pct','Knowledge Worker Percentage',x), inplace=True)\n",
    "inp.rename(columns=lambda x: re.sub('he_pct','Highly-Educated Percentage',x), inplace=True)\n",
    "inp.rename(columns=lambda x: re.sub('median_price_inf','Property Prices (Transformed)',x), inplace=True)\n",
    "\n",
    "# Save to file (note that we are also saving some info about the input variables as we use these as well)\n",
    "res[\n",
    "    ['RANK_11','RANK_21','SES_11','SES_21','SES_ASC','SES_PR_11','SES_PR_21','SES_PR_ASC']\n",
    "].to_csv(os.path.join(path_analytical,\"No transform\" + '-Scores.csv.gz'), compression='gzip', index=True, sep=\";\") \n",
    "inp[\n",
    "    [x for x in inp.columns if '2011' in x]\n",
    "].to_csv(os.path.join(path_scores,\"No transform\" + '-Inputs-2011.csv.gz'), compression='gzip', index=True, sep=\";\")\n",
    "inp[\n",
    "    [x for x in inp.columns if '2021' in x]\n",
    "].to_csv(os.path.join(path_scores,\"No transform\" + '-Inputs-2021.csv.gz'), compression='gzip', index=True, sep=\";\")\n",
    "\n",
    "res.to_csv(os.path.join(path_scores,\"Scores.csv\"),index=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668e2b9-ca04-406e-ae1a-4eea430cac03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
